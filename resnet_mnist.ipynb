{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_mnist",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1PLqX+3EB91pig1/BghdC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbeniteze/ResNets/blob/master/resnet_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3swsxrGRFDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install keras==2.3.1\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZQDhtT1OB1Q",
        "colab_type": "code",
        "outputId": "f8ea6a4e-84bc-4129-93cb-2432ae89d661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, Reshape\n",
        "from keras.layers import Flatten, BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][width][height][channels]\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVLROem5OLoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, Input, Activation, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'           #relu\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=7)(x)    #modificado de 8 a 7 por tamaño\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "    \n",
        "model = resnet_v2(input_shape=(28,28,1), depth=56)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6SbOo8hOTzr",
        "colab_type": "code",
        "outputId": "06a1c4e8-2dc7-4c8a-92cb-9c41b799b1d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Fit the model\n",
        "modelo = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        " \n",
        "print(\"Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 182s 3ms/step - loss: 1.1246 - accuracy: 0.9281 - val_loss: 1.7242 - val_accuracy: 0.5842\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.5773 - accuracy: 0.9859 - val_loss: 0.7435 - val_accuracy: 0.9125\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.4076 - accuracy: 0.9886 - val_loss: 0.5433 - val_accuracy: 0.9345\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.3177 - accuracy: 0.9898 - val_loss: 1.1175 - val_accuracy: 0.7828\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.2605 - accuracy: 0.9903 - val_loss: 0.4472 - val_accuracy: 0.9207\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.2209 - accuracy: 0.9911 - val_loss: 0.2552 - val_accuracy: 0.9765\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.1925 - accuracy: 0.9912 - val_loss: 0.1988 - val_accuracy: 0.9865\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.1686 - accuracy: 0.9920 - val_loss: 0.2103 - val_accuracy: 0.9779\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 160s 3ms/step - loss: 0.1516 - accuracy: 0.9925 - val_loss: 0.2878 - val_accuracy: 0.9501\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 159s 3ms/step - loss: 0.1400 - accuracy: 0.9925 - val_loss: 0.2090 - val_accuracy: 0.9703\n",
            "Error: 2.97%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}